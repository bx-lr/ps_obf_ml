{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "say what we are doing and why..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Team](#team)\n",
    "2. [Requirements](#requirements)\n",
    "3. [Setup](#setup)\n",
    "4. [Logistic Regression](#logistic-regression)\n",
    "    1. [Logistic Regression Model 1](#logistic-regression-model-1)\n",
    "    2. [Logistic Regression Model 2](#logistic-regression-model-2)\n",
    "5. [Support Vector Machines](#support-vector-machines)    \n",
    "    1. [SVM Model 1](#svm-model-1)\n",
    "    2. [SVM Model 2](#svm-model-2)\n",
    "6. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team\n",
    "- Adam Alidra\n",
    "- Ryan Herrin\n",
    "- Josh Mitchell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "- Create a logistic regression model and a support vector machine model for the classification task involved with your dataset. Assess how well each model performs (use 80/20 training/testing split for your data). Adjust parameters of the models to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. That is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. For many problems, SGD will be required in order to train the SVM model in a reasonable timeframe.\n",
    "- Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail.\n",
    "- Use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. Why do you think some variables are more important?\n",
    "- Look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain. If you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC modelâ€” then analyze the support vectors from the subsampled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "Import required libraries and read in our data. Next, we partition the data and use 80% for training and 20% for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# NOTE: Data imported has been generated from the first lab and turned into two data sets \n",
    "# + One data set is the raw data minus columns that had no values in them \n",
    "# + The other data set is data that had a transformation applied to it \n",
    "raw_data_location = '../dataset/raw_data.csv'\n",
    "transformed_data_location = '../dataset/transformed_data.csv'\n",
    "\n",
    "raw_data_df = pd.read_csv(raw_data_location)\n",
    "tf_data_df = pd.read_csv(transformed_data_location) # tf being shorthand for transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common random seed value and sample test percentage size \n",
    "seed_value = 8675309 # if you know you know\n",
    "test_sample_size = .2 # percentage \n",
    "\n",
    "# Split the data into a 80/20 Train/Testing for raw and trasnformed data \n",
    "# Using the split method from sklearn \n",
    "raw_train, raw_test = train_test_split(raw_data_df, test_size=test_sample_size, random_state=seed_value)\n",
    "tf_train, tf_test = train_test_split(tf_data_df, test_size=test_sample_size, random_state=seed_value)\n",
    "\n",
    "# Create Reusable Numpy arrays from the raw and transformed data to avoid using loc and iloc to seperate\n",
    "# the contents of the dataframes when training/testing\n",
    "\n",
    "# Raw Data ---\n",
    "raw_train_features = raw_train.iloc[:, 1:].to_numpy() # features to train without 'is_obf'\n",
    "raw_train_labels = raw_train.loc[:, 'is_obf'].to_numpy() # only 'is_obf'\n",
    "raw_test_features = raw_test.iloc[:, 1:].to_numpy() # features to create predictions\n",
    "raw_test_labels = raw_test.loc[:, 'is_obf'].to_numpy() # only 'is_obf' to test accuracy and get matrix with\n",
    "\n",
    "# Transformed Data ---\n",
    "tf_train_features = tf_train.iloc[:, 1:].to_numpy() # features to train without 'is_obf'\n",
    "tf_train_labels = tf_train.loc[:, 'is_obf'].to_numpy() # only 'is_obf'\n",
    "tf_test_features = tf_test.iloc[:, 1:].to_numpy() # features to create predictions\n",
    "tf_test_labels = tf_test.loc[:, 'is_obf'].to_numpy() # only 'is_obf' to test accuracy and get matrix with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "TODO: discuss parameter adjustment to make model more accurate\n",
    "\n",
    "TODO: discuss advantages of LR\n",
    "\n",
    "TODO: discuss performance of LR\n",
    "\n",
    "TODO: discuss importance of different features\n",
    "\n",
    "TODO: use time to see how long model training takes\n",
    "\n",
    "TODO: add visualization of each model (maybe show boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model 1\n",
    "Logistic regression model for the raw data set. Discuss the model performance (confusion matrix) and training time here. add visualization code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model for Raw Data #\n",
    "\n",
    "# Create Logistic Regression Object \n",
    "log_reg_raw = LogisticRegression(penalty='l2', C=1.0, class_weight=None, solver='liblinear', max_iter=150)\n",
    "\n",
    "# Train model with raw data input\n",
    "log_reg_raw.fit(raw_train_features, raw_train_labels)\n",
    "\n",
    "# Create predictions from model\n",
    "raw_log_reg_pred = log_reg_raw.predict(raw_test_features)\n",
    "\n",
    "# Get accuracy \n",
    "raw_log_reg_accuracy = mt.accuracy_score(\n",
    "    raw_test_labels, # Original lables (classifications)\n",
    "    raw_log_reg_pred # Predicted values\n",
    ")\n",
    "\n",
    "# Get confusion Matrix\n",
    "raw_log_reg_conf = mt.confusion_matrix(raw_test_labels, raw_log_reg_pred)\n",
    "\n",
    "# Display results\n",
    "print(\"Accuracy: \", raw_log_reg_accuracy)\n",
    "print(\"Confusion Matrix\\n\", raw_log_reg_conf)\n",
    "\n",
    "# Get the weights for each variable \n",
    "# sort these attributes and spit them out\n",
    "raw_logreg_vars = zip(log_reg_raw.coef_.T, raw_train.iloc[:, 1:])\n",
    "raw_logreg_vars = sorted(raw_logreg_vars)\n",
    "# Display Weights \n",
    "print('\\nFeature Weights\\n---------------------')\n",
    "for coef, name in raw_logreg_vars:\n",
    "    print(name, 'weight: ', coef[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model 2\n",
    "Logistic regression model for the transformed data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model for Transformed Data \n",
    "\n",
    "# Create Logistic Regression Object \n",
    "log_reg_tf = LogisticRegression(penalty='l2', C=1.0, class_weight=None, solver='liblinear', max_iter=150)\n",
    "\n",
    "# Train model with raw data input\n",
    "log_reg_tf.fit(tf_train_features, tf_train_labels)\n",
    "\n",
    "# Create predictions from model\n",
    "tf_log_reg_pred = log_reg_tf.predict(tf_test_features)\n",
    "\n",
    "# Get accuracy \n",
    "tf_log_reg_accuracy = mt.accuracy_score(\n",
    "    tf_test_labels, # Original lables (classifications)\n",
    "    tf_log_reg_pred # Predicted values\n",
    ")\n",
    "\n",
    "# Get confusion Matrix\n",
    "tf_log_reg_conf = mt.confusion_matrix(tf_test_labels, tf_log_reg_pred)\n",
    "\n",
    "# Display results\n",
    "print(\"Accuracy: \", tf_log_reg_accuracy)\n",
    "print(\"Confusion Matrix\\n\", tf_log_reg_conf)\n",
    "\n",
    "# Get the weights for each variable \n",
    "# sort these attributes and spit them out\n",
    "tf_logreg_vars = zip(log_reg_tf.coef_.T, tf_train.iloc[:, 1:])\n",
    "tf_logreg_vars = sorted(tf_logreg_vars)\n",
    "# Display Weights \n",
    "print('\\nFeature Weights\\n---------------------')\n",
    "for coef, name in tf_logreg_vars:\n",
    "    print(name, 'weight: ', coef[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "TODO: inspect support vectors\n",
    "\n",
    "TODO: discuss advantages of SVM\n",
    "\n",
    "TODO: discuss performance of SVM\n",
    "\n",
    "TODO: discuss importance of different features\n",
    "\n",
    "TODO: use time to see how long model training takes\n",
    "\n",
    "TODO: add visualization of each model (maybe show boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model 1\n",
    "Logistic regression model for the raw data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SVC classifier using an RBF kernel\n",
    "svm = SVC(kernel='rbf', random_state=0, gamma=.01, C=1)\n",
    "# Train the classifier\n",
    "svm.fit(X_xor, y_xor)\n",
    "\n",
    "# Visualize the decision boundaries\n",
    "plot_decision_regions(X_xor, y_xor, classifier=svm)\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SVC classifier using an RBF kernel\n",
    "svm = SVC(kernel='rbf', random_state=0, gamma=.01, C=1)\n",
    "# Train the classifier\n",
    "svm.fit(X_xor, y_xor)\n",
    "\n",
    "# Visualize the decision boundaries\n",
    "plot_decision_regions(X_xor, y_xor, classifier=svm)\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "which model was better? Why? \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "044be36d561837db4cca478848e4fb2d2ece9bde8e5960d88b052ad890d04b2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
